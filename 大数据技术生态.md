hive底层计算：mapreduce/spark

hadoop、spark：hadoop是基于文件的数据结构，spark是基于rdd的数据结构，计算性能要比hadoop高

reference：  
1.[如何用形象的比喻描述大数据的技术生态？Hadoop、Hive、Spark 之间是什么关系？](https://www.zhihu.com/question/27974418)

大数据技术本质上解决4个核心问题：  
1.存储，海量的数据怎样有效的存储？主要包括hdfs、Kafka；  
2.计算，海量的数据怎样快速计算？主要包括MapReduce、Spark、Flink等；  
3.查询，海量数据怎样快速查询？主要为Nosql和OLAP。Nosql主要包括Hbase、Cassandra等，OLAP包括kylin、impla等。Nosql主要解决随机查询，OLAP技术主要解决关联查询；  
4.挖掘，海量数据怎样挖掘出隐藏的知识？也就是当前火热的机器学习和深度学习等技术，包括TensorFlow、caffe、mahout等；



hive底层计算：MapReduce/Spark

hadoop是基于文件的数据结构;  
spark是基于RDD的数据结构，计算性能要比hadoop高



## hadoop / hive / hbase 的区别
**hadoop**  
一个分布式计算+分布式文件系统，前者其实就是 MapReduce，后者是 HDFS 。  
后者可以独立运行，前者可以选择性使用，也可以不使用  
**hive**  
通俗的说是一个数据仓库，仓库中的数据是被hdfs管理的数据文件，它支持类似sql语句的功能，你可以通过该语句完成分布式环境下的计算功能，hive会把语句转换成MapReduce，然后交给hadoop执行。  
这里的计算，仅限于查找和分析，而不是更新、增加和删除。  
它的优势是对历史数据进行处理，用时下流行的说法是离线计算，因为它的底层是MapReduce，MapReduce在实时计算上性能很差。  
它的做法是把数据文件加载进来作为一个hive表（或者外部表），让你觉得你的sql操作的是传统的表。  
**hbase**  
通俗的说，hbase的作用类似于数据库，传统数据库管理的是集中的本地数据文件，而hbase基于hdfs实现对分布式数据文件的管理，比如增删改查。  
也就是说，**hbase只是利用hadoop的hdfs帮助其管理数据的持久化文件（HFile），它跟MapReduce没任何关系**。  
hbase的优势在于实时计算，所有实时数据都直接存入hbase中，客户端通过API直接访问hbase，实现实时计算。  
由于它使用的是nosql，或者说是列式结构，从而提高了查找性能，使其能运用于大数据场景，这是它跟MapReduce的区别。
### 总结
**hadoop是hive和hbase的基础，hive依赖hadoop，而hbase仅依赖hadoop的hdfs模块。**  
**hive适用于离线数据的分析**，操作的是通用格式的（如通用的日志文件）、被hadoop管理的数据文件，它支持类sql，比编写MapReduce的java代码来的更加方便，它的定位是数据仓库，存储和分析历史数据。  
**hbase适用于实时计算，采用列式结构的nosql**，操作的是自己生成的特殊格式的HFile、被hadoop管理的数据文件，它的定位是数据库，或者叫DBMS。  
hive可以直接操作hdfs中的文件作为它的表的数据，也可以使用hbase数据库作为它的表。



reference：  
1.[如何用形象的比喻描述大数据的技术生态？](https://www.zhihu.com/question/27974418)

## <p><strong>什么是数据倾斜</strong> <br>
&nbsp;&nbsp;&nbsp;&nbsp;简单的讲，数据倾斜就是我们在计算数据的时候，数据的分散度不够，导致大量的数据集中到了一台或者几台机器上计算，这些数据的计算速度远远低于平均计算速度，导致整个计算过程过慢。 <br>
&nbsp;&nbsp;&nbsp;&nbsp;相信大部分做数据的童鞋们都会遇到数据倾斜，数据倾斜会发生在数据开发的各个环节中，比如：</p>

<ul>
<li>用Hive算数据的时候reduce阶段卡在99.99%</li>
<li><p>用SparkStreaming做实时算法时候，一直会有executor出现OOM的错误，但是其余的executor内存使用率却很低。 <br>
&nbsp;&nbsp;&nbsp;&nbsp;数据倾斜有一个关键因素是数据量大，可以达到千亿级。</p>

<p><strong>数据倾斜长的表现</strong></p></li>
</ul>

<p>&nbsp;&nbsp;&nbsp;&nbsp;以Hadoop和Spark是最常见的两个计算平台，下面就以这两个平台说明：</p>

<p>1、Hadoop中的数据倾斜</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;Hadoop中直接贴近用户使用使用的时Mapreduce程序和Hive程序，虽说Hive最后也是用MR来执行（至少目前Hive内存计算并不普及），但是毕竟写的内容逻辑区别很大，一个是程序，一个是Sql，因此这里稍作区分。</p>

<p>Hadoop中的数据倾斜主要表现在ruduce阶段卡在99.99%，一直99.99%不能结束。 <br>
这里如果详细的看日志或者和监控界面的话会发现：</p>

<ul>
<li>有一个多几个reduce卡住</li>
<li>各种container报错OOM</li>
<li>读写的数据量极大，至少远远超过其它正常的reduce <br>
伴随着数据倾斜，会出现任务被kill等各种诡异的表现。</li>
</ul>

<p><strong>经验：</strong> Hive的数据倾斜，一般都发生在Sql中Group和On上，而且和数据逻辑绑定比较深。</p>

<p>2、Spark中的数据倾斜</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;Spark中的数据倾斜也很常见，这里包括Spark Streaming和Spark Sql，表现主要有下面几种：</p>

<ul>
<li>Executor lost，OOM，Shuffle过程出错</li>
<li>Driver OOM</li>
<li>单个Executor执行时间特别久，整体任务卡在某个阶段不能结束</li>
<li>正常运行的任务突然失败</li>
</ul>

<p>补充一下，在Spark streaming程序中，数据倾斜更容易出现，特别是在程序中包含一些类似sql的join、group这种操作的时候。 因为Spark Streaming程序在运行的时候，我们一般不会分配特别多的内存，因此一旦在这个过程中出现一些数据倾斜，就十分容易造成OOM。</p>

<p><strong>数据倾斜的原理</strong></p>

<p>1、数据倾斜产生的原因 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们以Spark和Hive的使用场景为例。他们在做数据运算的时候会设计到，countdistinct、group by、join等操作，这些都会触发Shuffle动作，一旦触发，所有相同key的值就会拉到一个或几个节点上，就容易发生单点问题。</p>

<p>2、万恶的shuffle <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Shuffle是一个能产生奇迹的地方，不管是在Spark还是Hadoop中，它们的作用都是至关重要的。那么在Shuffle如何产生了数据倾斜？</p>

<p>Hadoop和Spark在Shuffle过程中产生数据倾斜的原理基本类似。如下图。 <br>
</p><center><img src="https://img-blog.csdn.net/20170905164538706?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvdTAxMDAzOTkyOQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title=""> </center> <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;大部分数据倾斜的原理就类似于下图，很明了，因为数据分布不均匀，导致大量的数据分配到了一个节点。<p></p>

<p>3、从业务计角度来理解数据倾斜 </p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据往往和业务是强相关的，业务的场景直接影响到了数据的分布。再举一个例子，比如就说订单场景吧，我们在某一天在北京和上海两个城市多了强力的推广，结果可能是这两个城市的订单量增长了10000%，其余城市的数据量不变。然后我们要统计不同城市的订单情况，这样，一做group操作，可能直接就数据倾斜了。</p>

<p><strong>如何解决</strong></p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据倾斜的产生是有一些讨论的，解决它们也是有一些讨论的，本章会先给出几个解决数据倾斜的思路，然后对Hadoop和Spark分别给出一些解决数据倾斜的方案。 <br>
一、几个思路 <br>
&nbsp;&nbsp;&nbsp;&nbsp;解决数据倾斜有这几个思路： <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.业务逻辑，我们从业务逻辑的层面上来优化数据倾斜，比如上面的例子，我们单独对这两个城市来做count，最后和其它城市做整合。 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.程序层面，比如说在Hive中，经常遇到count（distinct）操作，这样会导致最终只有一个reduce，我们可以先group 再在外面包一层count，就可以了。 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.调参方面，Hadoop和Spark都自带了很多的参数和机制来调节数据倾斜，合理利用它们就能解决大部分问题。</p>

<p>二、从业务和数据上解决数据倾斜</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;很多数据倾斜都是在数据的使用上造成的。我们举几个场景，并分别给出它们的解决方案。 <br>
数据分布不均匀： <br>
前面提到的“从数据角度来理解数据倾斜”和“从业务计角度来理解数据倾斜”中的例子，其实都是数据分布不均匀的类型，这种情况和计算平台无关，我们能通过设计的角度尝试解决它。</p>

<ul>
<li>有损的方法： <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;找到异常数据，比如ip为0的数据，过滤掉</li>
<li>无损的方法： <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对分布不均匀的数据，单独计算 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先对key做一层hash，先将数据打散让它的并行度变大，再汇集 <br>
•数据预处理</li>
</ul>

<p>三、Hadoop平台的优化方法</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;列出来一些方法和思路，具体的参数和用法在官网看就行了。</p>

<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.mapjoin方式 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.count distinct的操作，先转成group，再count <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.hive.groupby.skewindata=true <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.left semi jioin的使用 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;5.设置map端输出、中间结果压缩。（不完全是解决数据倾斜的问题，但是减少了IO读写和网络传输，能提高很多效率）</p>

<p>四、Spark平台的优化方法 <br>
&nbsp;&nbsp;&nbsp;&nbsp;列出来一些方法和思路，具体的参数和用法在官网看就行了。 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;1.mapjoin方式 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.设置rdd压缩 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;3.合理设置driver的内存 <br>
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;4.Spark Sql中的优化和Hive类似，可以参考Hive</p>

<p>总结</p>

<p>数据倾斜的坑还是很大的，如何处理数据倾斜是一个长期的过程，希望本文的一些思路能提供帮助。文中一些内容没有细讲，比如Hive Sql的优化，数据清洗中的各种坑，这些留待后面单独的分享，会有很多的内容。另外千亿级别的数据还会有更多的难点，不仅仅是数据倾斜的问题，这一点在后面也会有专门的分享。</p>                                    </div>

&nbsp;
## count(distinct)转group by
在Hive中，为了防止出现数据倾斜，我们会尽量避免使用count(distinct)，一般我们会使用group by进行替换.   
测试表表结构  
```
CREATE TABLE IF NOT EXISTS test_01 (
school_id int COMMENT '学校id',
name string COMMENT '姓名',
level string COMMENT '综合评级',
class_name string COMMENT '所属班级'
) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',';
```
测试表表数据  
```
hive (test)> select * from test_01;
OK
1	Lucy	s	c_01
1	Marry	s	c_01
1	Jack	a	c_02
1	Tom		a	c_02
1	Rose	a	c_03
1	Curry	b	c_03
1	Tonny	c	c_03
```
这里统计不同的综合评级和班级，使用count(distinct)查询结果  
```
hive (test)> select 
school_id,
count(distinct level) ,
count(distinct class_name) 
from test_01 group by school_id;

OK
1	4	3
```
使用group by查询结果，这里我们**采用通过空间换时间的思想来将count(distinct)转换成group by函数**  
```
//通过空间换时间
hive (test)> select 
school_id,
count(case when type = 'a' then 1 else null end) as num1,
count(case when type = 'b' then 1 else null end) as num2 from (
select school_id,level as col,'a' as type from test_01
union 
select school_id,class_name as col,'b' as type from test_01) t
group by school_id;

OK
1	4	3
```
符合预期！

注意：不要使用union all，否则会与预期不相符！
```
select 
school_id,
count(case when type = 'a' then 1 else null end) as num1,
count(case when type = 'b' then 1 else null end) as num2 from (
select school_id,level as col,'a' as type from test_01
union all
select school_id,class_name as col,'b' as type from test_01) t
group by school_id;

OK
1	7	7
```

&nbsp;
## referene
[大数据常见问题之数据倾斜](https://blog.csdn.net/u010039929/article/details/55044407)  
[]()
